{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Ensembles\n",
    "\n",
    "В задачах нужно корректно реализовать функции, чтобы проходили тесты. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jvls9GQxWK5O"
   },
   "source": [
    "## 1. Bootstrap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9POKe84XWK6A"
   },
   "source": [
    "### Алгоритм Bootstrap \n",
    "* Равномерно возьмем из выборки $N$ объектов **с возвращением**. То есть мы хотим сгенерировать псевдовыборку, в которой могут повторятся элементы из исходной выборки. \n",
    "\n",
    "* Обозначим новую выборку через $X_1$. Повторяя процедуру $B$ раз, сгенерируем $M$ подвыборок $X_1, \\dots, X_B$. \n",
    "\n",
    "* Посчитаем статистику T от каждой выборки $(T(X_1), \\ldots, T(X_n))$\n",
    "\n",
    "* Найдем итоговую статистику $T(X) = \\frac{1}{B}\\sum^{B}_{i}T(X_i)$\n",
    "\n",
    "На вход массив чисел $X$ и число бутстрепных выборок $B$. Необходимо реализовать свой бутстреп и найти матожидание и стандартную ошибку у бутстрепных выборок.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oNTDVikgWK6F"
   },
   "source": [
    "### TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_awC3d6CWK6I"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import sem # ищет SE среднего\n",
    "import random\n",
    "\n",
    "def get_stats(X, B):\n",
    "    n = len(X)\n",
    "    bootstrap = []\n",
    "    for j in range(B):\n",
    "        x_j = []\n",
    "        for i in range(n):\n",
    "            x_j.append(random.choice(X))\n",
    "        bootstrap.append(x_j)\n",
    "    bootstrap = np.array(bootstrap)\n",
    "    mean = bootstrap.mean().mean()\n",
    "    SE = sem(bootstrap, axis=1).mean()\n",
    "    return mean, SE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "X = np.array([37,43,38,36,17,40,40,45,41,84])\n",
    "B = 100000\n",
    "\n",
    "mean, se = get_stats(X, B)\n",
    "\n",
    "assert np.abs(mean - 42.1) < 0.05\n",
    "assert np.abs(se - 4.56) < 0.03\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо реализовать свой небольшой беггинг на деревьях заданной грубины\n",
    "\n",
    "* бустингом сделать несколько выборок $X_1, \\ldots, X_B$\n",
    "* обучить на этих выборках алгоритмы: $a_1(\\cdot), \\ldots, a_B(\\cdot)$\n",
    "\n",
    "Получить результат беггинга как:\n",
    "$$a(x) = \\frac{1}{B}\\sum_{b=1}^{B}a_b(x)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor as DTR\n",
    "\n",
    "def bagging(X_train, y_train, X_test, boot_count, depth):\n",
    "    estimators = np.array([DTR(max_depth=depth) for _ in range(boot_count)])\n",
    "    a = []\n",
    "    for i in range(boot_count):\n",
    "        X_i = []\n",
    "        y_i = []\n",
    "        n = len(X_train)\n",
    "        for j in range(n):\n",
    "            indx = random.choice(np.arange(n))\n",
    "            X_i.append(X_train[indx])\n",
    "            y_i.append(y_train[indx])\n",
    "        estimators[i].fit(X_i, y_i)\n",
    "        a.append(estimators[i].predict(X_test))\n",
    "        \n",
    "    a = np.array(a)    \n",
    "    y_pred = a.mean(axis=0)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.644658046052632\n",
      "19.569407894736845\n",
      "13.888794071158092\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.testing import assert_array_equal, assert_array_almost_equal, assert_equal, assert_almost_equal\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "######################################################\n",
    "\n",
    "X_train = np.array([[0, 0], [1, 1], [5, 5], [8, 8], [10, 10]])\n",
    "y_train = np.array([0, 1, 5, 8, 10])\n",
    "X_test  = np.array([[4, 4], [6, 6]])\n",
    "y_test  = np.array([4, 6])\n",
    "\n",
    "B = 1000\n",
    "\n",
    "y_pred = bagging(X_train, y_train, X_test, boot_count=B, depth=3)\n",
    "\n",
    "assert_array_almost_equal(y_pred, np.array([4, 6]), decimal=0)\n",
    "\n",
    "######################################################\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "X, y = load_boston(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "\n",
    "y_pred = bagging(X_train, y_train, X_test, boot_count=200, depth=10)\n",
    "\n",
    "y_dt_pred = DecisionTreeRegressor().fit(X_train, y_train).predict(X_test)\n",
    "y = RandomForestRegressor().fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "print(mean_squared_error(y, y_test))\n",
    "print(mean_squared_error(y_dt_pred, y_test))\n",
    "print(mean_squared_error(y_pred, y_test))\n",
    "assert mean_squared_error(y_pred, y_test) < 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. X-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо найти наилучшие параметры для XGBRegression, обучить модель и вернуть ее. Данные берутся из папки data.\n",
    "\n",
    "Сам гридсерч или нативное исследование необходимо делать вне функции обработки, чтобы не получить TL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   21.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:27:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:27:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:3.04251\tvalidation_1-rmse:1.50203\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[1]\tvalidation_0-rmse:3.00978\tvalidation_1-rmse:1.47678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  72 out of  72 | elapsed:   29.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\tvalidation_0-rmse:2.97794\tvalidation_1-rmse:1.45182\n",
      "[3]\tvalidation_0-rmse:2.94770\tvalidation_1-rmse:1.43253\n",
      "[4]\tvalidation_0-rmse:2.91888\tvalidation_1-rmse:1.40990\n",
      "[5]\tvalidation_0-rmse:2.88982\tvalidation_1-rmse:1.39007\n",
      "[6]\tvalidation_0-rmse:2.86197\tvalidation_1-rmse:1.37102\n",
      "[7]\tvalidation_0-rmse:2.83572\tvalidation_1-rmse:1.35301\n",
      "[8]\tvalidation_0-rmse:2.81040\tvalidation_1-rmse:1.33622\n",
      "[9]\tvalidation_0-rmse:2.78587\tvalidation_1-rmse:1.32183\n",
      "[10]\tvalidation_0-rmse:2.76221\tvalidation_1-rmse:1.30478\n",
      "[11]\tvalidation_0-rmse:2.73858\tvalidation_1-rmse:1.29140\n",
      "[12]\tvalidation_0-rmse:2.71607\tvalidation_1-rmse:1.27949\n",
      "[13]\tvalidation_0-rmse:2.69440\tvalidation_1-rmse:1.26477\n",
      "[14]\tvalidation_0-rmse:2.67324\tvalidation_1-rmse:1.25541\n",
      "[15]\tvalidation_0-rmse:2.65262\tvalidation_1-rmse:1.24203\n",
      "[16]\tvalidation_0-rmse:2.63297\tvalidation_1-rmse:1.23567\n",
      "[17]\tvalidation_0-rmse:2.61362\tvalidation_1-rmse:1.22893\n",
      "[18]\tvalidation_0-rmse:2.59490\tvalidation_1-rmse:1.21781\n",
      "[19]\tvalidation_0-rmse:2.57631\tvalidation_1-rmse:1.21226\n",
      "[20]\tvalidation_0-rmse:2.55872\tvalidation_1-rmse:1.20171\n",
      "[21]\tvalidation_0-rmse:2.54158\tvalidation_1-rmse:1.19862\n",
      "[22]\tvalidation_0-rmse:2.52448\tvalidation_1-rmse:1.19513\n",
      "[23]\tvalidation_0-rmse:2.50836\tvalidation_1-rmse:1.18766\n",
      "[24]\tvalidation_0-rmse:2.49306\tvalidation_1-rmse:1.18516\n",
      "[25]\tvalidation_0-rmse:2.47767\tvalidation_1-rmse:1.17546\n",
      "[26]\tvalidation_0-rmse:2.46237\tvalidation_1-rmse:1.17433\n",
      "[27]\tvalidation_0-rmse:2.44729\tvalidation_1-rmse:1.17359\n",
      "[28]\tvalidation_0-rmse:2.43290\tvalidation_1-rmse:1.16613\n",
      "[29]\tvalidation_0-rmse:2.41856\tvalidation_1-rmse:1.16718\n",
      "[30]\tvalidation_0-rmse:2.40486\tvalidation_1-rmse:1.16733\n",
      "[31]\tvalidation_0-rmse:2.39139\tvalidation_1-rmse:1.16907\n",
      "[32]\tvalidation_0-rmse:2.37830\tvalidation_1-rmse:1.16291\n",
      "[33]\tvalidation_0-rmse:2.36584\tvalidation_1-rmse:1.15687\n",
      "[34]\tvalidation_0-rmse:2.35306\tvalidation_1-rmse:1.15775\n",
      "[35]\tvalidation_0-rmse:2.34090\tvalidation_1-rmse:1.16060\n",
      "[36]\tvalidation_0-rmse:2.32905\tvalidation_1-rmse:1.16580\n",
      "[37]\tvalidation_0-rmse:2.31779\tvalidation_1-rmse:1.16901\n",
      "[38]\tvalidation_0-rmse:2.30589\tvalidation_1-rmse:1.16358\n",
      "[39]\tvalidation_0-rmse:2.29460\tvalidation_1-rmse:1.15807\n",
      "[40]\tvalidation_0-rmse:2.28395\tvalidation_1-rmse:1.15331\n",
      "[41]\tvalidation_0-rmse:2.27326\tvalidation_1-rmse:1.15913\n",
      "[42]\tvalidation_0-rmse:2.26286\tvalidation_1-rmse:1.16364\n",
      "[43]\tvalidation_0-rmse:2.25225\tvalidation_1-rmse:1.16674\n",
      "[44]\tvalidation_0-rmse:2.24209\tvalidation_1-rmse:1.16254\n",
      "[45]\tvalidation_0-rmse:2.23196\tvalidation_1-rmse:1.16797\n",
      "[46]\tvalidation_0-rmse:2.22202\tvalidation_1-rmse:1.17238\n",
      "[47]\tvalidation_0-rmse:2.21256\tvalidation_1-rmse:1.16802\n",
      "[48]\tvalidation_0-rmse:2.20305\tvalidation_1-rmse:1.17431\n",
      "[49]\tvalidation_0-rmse:2.19347\tvalidation_1-rmse:1.17975\n",
      "[50]\tvalidation_0-rmse:2.18441\tvalidation_1-rmse:1.18705\n",
      "[51]\tvalidation_0-rmse:2.17529\tvalidation_1-rmse:1.18333\n",
      "[52]\tvalidation_0-rmse:2.16653\tvalidation_1-rmse:1.18847\n",
      "[53]\tvalidation_0-rmse:2.15805\tvalidation_1-rmse:1.18606\n",
      "[54]\tvalidation_0-rmse:2.14931\tvalidation_1-rmse:1.19311\n",
      "[55]\tvalidation_0-rmse:2.14046\tvalidation_1-rmse:1.19855\n",
      "[56]\tvalidation_0-rmse:2.13240\tvalidation_1-rmse:1.19690\n",
      "[57]\tvalidation_0-rmse:2.12459\tvalidation_1-rmse:1.20263\n",
      "[58]\tvalidation_0-rmse:2.11633\tvalidation_1-rmse:1.20791\n",
      "[59]\tvalidation_0-rmse:2.10856\tvalidation_1-rmse:1.20612\n",
      "[60]\tvalidation_0-rmse:2.10108\tvalidation_1-rmse:1.21375\n",
      "[61]\tvalidation_0-rmse:2.09351\tvalidation_1-rmse:1.21161\n",
      "[62]\tvalidation_0-rmse:2.08583\tvalidation_1-rmse:1.21930\n",
      "[63]\tvalidation_0-rmse:2.07830\tvalidation_1-rmse:1.22588\n",
      "[64]\tvalidation_0-rmse:2.07090\tvalidation_1-rmse:1.22314\n",
      "[65]\tvalidation_0-rmse:2.06353\tvalidation_1-rmse:1.22967\n",
      "[66]\tvalidation_0-rmse:2.05665\tvalidation_1-rmse:1.23718\n",
      "[67]\tvalidation_0-rmse:2.04939\tvalidation_1-rmse:1.23350\n",
      "[68]\tvalidation_0-rmse:2.04204\tvalidation_1-rmse:1.24117\n",
      "[69]\tvalidation_0-rmse:2.03540\tvalidation_1-rmse:1.24868\n",
      "[70]\tvalidation_0-rmse:2.02849\tvalidation_1-rmse:1.24638\n",
      "[71]\tvalidation_0-rmse:2.02130\tvalidation_1-rmse:1.25226\n",
      "[72]\tvalidation_0-rmse:2.01481\tvalidation_1-rmse:1.25873\n",
      "[73]\tvalidation_0-rmse:2.00806\tvalidation_1-rmse:1.25625\n",
      "[74]\tvalidation_0-rmse:2.00114\tvalidation_1-rmse:1.26363\n",
      "[75]\tvalidation_0-rmse:1.99458\tvalidation_1-rmse:1.27123\n",
      "[76]\tvalidation_0-rmse:1.98844\tvalidation_1-rmse:1.27775\n",
      "[77]\tvalidation_0-rmse:1.98178\tvalidation_1-rmse:1.28530\n",
      "[78]\tvalidation_0-rmse:1.97532\tvalidation_1-rmse:1.28141\n",
      "[79]\tvalidation_0-rmse:1.96981\tvalidation_1-rmse:1.28733\n",
      "[80]\tvalidation_0-rmse:1.96376\tvalidation_1-rmse:1.28420\n",
      "[81]\tvalidation_0-rmse:1.95786\tvalidation_1-rmse:1.29011\n",
      "[82]\tvalidation_0-rmse:1.95158\tvalidation_1-rmse:1.28689\n",
      "[83]\tvalidation_0-rmse:1.94582\tvalidation_1-rmse:1.29301\n",
      "[84]\tvalidation_0-rmse:1.94006\tvalidation_1-rmse:1.30085\n",
      "[85]\tvalidation_0-rmse:1.93377\tvalidation_1-rmse:1.29755\n",
      "[86]\tvalidation_0-rmse:1.92822\tvalidation_1-rmse:1.30327\n",
      "[87]\tvalidation_0-rmse:1.92161\tvalidation_1-rmse:1.31079\n",
      "[88]\tvalidation_0-rmse:1.91520\tvalidation_1-rmse:1.31859\n",
      "[89]\tvalidation_0-rmse:1.90934\tvalidation_1-rmse:1.31456\n",
      "[90]\tvalidation_0-rmse:1.90418\tvalidation_1-rmse:1.32063\n",
      "[91]\tvalidation_0-rmse:1.89823\tvalidation_1-rmse:1.32851\n",
      "[92]\tvalidation_0-rmse:1.89270\tvalidation_1-rmse:1.32482\n",
      "[93]\tvalidation_0-rmse:1.88704\tvalidation_1-rmse:1.32439\n",
      "[94]\tvalidation_0-rmse:1.88165\tvalidation_1-rmse:1.33115\n",
      "[95]\tvalidation_0-rmse:1.87658\tvalidation_1-rmse:1.33700\n",
      "[96]\tvalidation_0-rmse:1.87139\tvalidation_1-rmse:1.34277\n",
      "[97]\tvalidation_0-rmse:1.86543\tvalidation_1-rmse:1.35122\n",
      "[98]\tvalidation_0-rmse:1.85997\tvalidation_1-rmse:1.34842\n",
      "[99]\tvalidation_0-rmse:1.85497\tvalidation_1-rmse:1.35408\n",
      "[100]\tvalidation_0-rmse:1.85026\tvalidation_1-rmse:1.36082\n",
      "[101]\tvalidation_0-rmse:1.84455\tvalidation_1-rmse:1.36849\n",
      "[102]\tvalidation_0-rmse:1.83974\tvalidation_1-rmse:1.37528\n",
      "[103]\tvalidation_0-rmse:1.83414\tvalidation_1-rmse:1.38286\n",
      "[104]\tvalidation_0-rmse:1.82828\tvalidation_1-rmse:1.38070\n",
      "[105]\tvalidation_0-rmse:1.82387\tvalidation_1-rmse:1.37876\n",
      "[106]\tvalidation_0-rmse:1.81912\tvalidation_1-rmse:1.38467\n",
      "[107]\tvalidation_0-rmse:1.81431\tvalidation_1-rmse:1.39043\n",
      "[108]\tvalidation_0-rmse:1.80925\tvalidation_1-rmse:1.38631\n",
      "[109]\tvalidation_0-rmse:1.80370\tvalidation_1-rmse:1.39481\n",
      "[110]\tvalidation_0-rmse:1.79899\tvalidation_1-rmse:1.40023\n",
      "[111]\tvalidation_0-rmse:1.79457\tvalidation_1-rmse:1.40697\n",
      "[112]\tvalidation_0-rmse:1.78958\tvalidation_1-rmse:1.40268\n",
      "[113]\tvalidation_0-rmse:1.78419\tvalidation_1-rmse:1.40972\n",
      "[114]\tvalidation_0-rmse:1.77961\tvalidation_1-rmse:1.41509\n",
      "[115]\tvalidation_0-rmse:1.77459\tvalidation_1-rmse:1.41198\n",
      "[116]\tvalidation_0-rmse:1.77017\tvalidation_1-rmse:1.41724\n",
      "[117]\tvalidation_0-rmse:1.76500\tvalidation_1-rmse:1.42468\n",
      "[118]\tvalidation_0-rmse:1.76033\tvalidation_1-rmse:1.43123\n",
      "[119]\tvalidation_0-rmse:1.75559\tvalidation_1-rmse:1.42818\n",
      "[120]\tvalidation_0-rmse:1.75151\tvalidation_1-rmse:1.43478\n",
      "[121]\tvalidation_0-rmse:1.74694\tvalidation_1-rmse:1.43157\n",
      "[122]\tvalidation_0-rmse:1.74193\tvalidation_1-rmse:1.43979\n",
      "[123]\tvalidation_0-rmse:1.73763\tvalidation_1-rmse:1.44510\n",
      "[124]\tvalidation_0-rmse:1.73288\tvalidation_1-rmse:1.45096\n",
      "[125]\tvalidation_0-rmse:1.72792\tvalidation_1-rmse:1.44768\n",
      "[126]\tvalidation_0-rmse:1.72364\tvalidation_1-rmse:1.44460\n",
      "[127]\tvalidation_0-rmse:1.71929\tvalidation_1-rmse:1.45097\n",
      "[128]\tvalidation_0-rmse:1.71430\tvalidation_1-rmse:1.45902\n",
      "[129]\tvalidation_0-rmse:1.71045\tvalidation_1-rmse:1.46470\n",
      "[130]\tvalidation_0-rmse:1.70606\tvalidation_1-rmse:1.46149\n",
      "[131]\tvalidation_0-rmse:1.70109\tvalidation_1-rmse:1.46897\n",
      "[132]\tvalidation_0-rmse:1.69697\tvalidation_1-rmse:1.47411\n",
      "[133]\tvalidation_0-rmse:1.69278\tvalidation_1-rmse:1.48033\n",
      "[134]\tvalidation_0-rmse:1.68805\tvalidation_1-rmse:1.48768\n",
      "[135]\tvalidation_0-rmse:1.68360\tvalidation_1-rmse:1.49140\n",
      "[136]\tvalidation_0-rmse:1.67904\tvalidation_1-rmse:1.49699\n",
      "[137]\tvalidation_0-rmse:1.67511\tvalidation_1-rmse:1.50271\n",
      "[138]\tvalidation_0-rmse:1.67081\tvalidation_1-rmse:1.49945\n",
      "[139]\tvalidation_0-rmse:1.66713\tvalidation_1-rmse:1.50484\n",
      "[140]\tvalidation_0-rmse:1.66290\tvalidation_1-rmse:1.50842\n",
      "Stopping. Best iteration:\n",
      "[40]\tvalidation_0-rmse:2.28395\tvalidation_1-rmse:1.15331\n",
      "\n",
      "[17:27:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, gamma=None,\n",
       "                                    gpu_id=None, importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=100, n_jobs=...\n",
       "                                    reg_alpha=None, reg_lambda=None,\n",
       "                                    scale_pos_weight=None, subsample=None,\n",
       "                                    tree_method=None, validate_parameters=None,\n",
       "                                    verbosity=None),\n",
       "             n_jobs=2,\n",
       "             param_grid={'colsample_bytree': [0.7, 0.8],\n",
       "                         'learning_rate': [0.01, 0.03, 0.05],\n",
       "                         'max_depth': [3, 4, 5, 6, 7, 7],\n",
       "                         'min_child_weight': [4], 'n_estimators': [500],\n",
       "                         'nthread': [4], 'objective': ['reg:linear'],\n",
       "                         'silent': [1], 'subsample': [1]},\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBRegressor()\n",
    "parameters = {'nthread': [4],\n",
    "              'objective': ['reg:linear'],\n",
    "              'learning_rate': [0.01, 0.03, 0.05],\n",
    "              'max_depth': [3, 4, 5, 6, 7, 7],\n",
    "              'min_child_weight': [4],\n",
    "              'silent': [1],\n",
    "              'subsample': [1],\n",
    "              'colsample_bytree': [0.7, 0.8],\n",
    "              'n_estimators': [500]}\n",
    "xgb_grid = GridSearchCV(xgb, parameters, cv=2, n_jobs=2,\n",
    "                        verbose=True)\n",
    "xgb_grid.fit(X_train, y_train,\n",
    "             eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "             early_stopping_rounds=100,\n",
    "             verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xreg(X_train: np.array, y_train:np.array) -> XGBRegressor:\n",
    "    model = xgb_grid.best_estimator_\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well Done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "df = pd.read_csv('data/Financial Distress.csv')\n",
    "\n",
    "X = df.drop('Financial Distress', axis=1)\n",
    "y = df['Financial Distress']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=17)\n",
    "\n",
    "t1 = time.time()\n",
    "xgb_model = xreg(X_train, y_train)\n",
    "t2 = time.time()\n",
    "\n",
    "assert t2 - t1 < 10\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "assert type(xgb_model) == xgboost.sklearn.XGBRegressor\n",
    "assert MSE(y_pred, y_test) < 3\n",
    "print('Well Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   17.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:23:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:23:11] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:3.04251\tvalidation_1-rmse:1.50203\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[1]\tvalidation_0-rmse:3.00978\tvalidation_1-rmse:1.47678\n",
      "[2]\tvalidation_0-rmse:2.97794\tvalidation_1-rmse:1.45182\n",
      "[3]\tvalidation_0-rmse:2.94770\tvalidation_1-rmse:1.43253\n",
      "[4]\tvalidation_0-rmse:2.91888\tvalidation_1-rmse:1.40990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  72 out of  72 | elapsed:   27.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\tvalidation_0-rmse:2.88982\tvalidation_1-rmse:1.39007\n",
      "[6]\tvalidation_0-rmse:2.86197\tvalidation_1-rmse:1.37102\n",
      "[7]\tvalidation_0-rmse:2.83572\tvalidation_1-rmse:1.35301\n",
      "[8]\tvalidation_0-rmse:2.81040\tvalidation_1-rmse:1.33622\n",
      "[9]\tvalidation_0-rmse:2.78587\tvalidation_1-rmse:1.32183\n",
      "[10]\tvalidation_0-rmse:2.76221\tvalidation_1-rmse:1.30478\n",
      "[11]\tvalidation_0-rmse:2.73858\tvalidation_1-rmse:1.29140\n",
      "[12]\tvalidation_0-rmse:2.71607\tvalidation_1-rmse:1.27949\n",
      "[13]\tvalidation_0-rmse:2.69440\tvalidation_1-rmse:1.26477\n",
      "[14]\tvalidation_0-rmse:2.67324\tvalidation_1-rmse:1.25541\n",
      "[15]\tvalidation_0-rmse:2.65262\tvalidation_1-rmse:1.24203\n",
      "[16]\tvalidation_0-rmse:2.63297\tvalidation_1-rmse:1.23567\n",
      "[17]\tvalidation_0-rmse:2.61362\tvalidation_1-rmse:1.22893\n",
      "[18]\tvalidation_0-rmse:2.59490\tvalidation_1-rmse:1.21781\n",
      "[19]\tvalidation_0-rmse:2.57631\tvalidation_1-rmse:1.21226\n",
      "[20]\tvalidation_0-rmse:2.55872\tvalidation_1-rmse:1.20171\n",
      "[21]\tvalidation_0-rmse:2.54158\tvalidation_1-rmse:1.19862\n",
      "[22]\tvalidation_0-rmse:2.52448\tvalidation_1-rmse:1.19513\n",
      "[23]\tvalidation_0-rmse:2.50836\tvalidation_1-rmse:1.18766\n",
      "[24]\tvalidation_0-rmse:2.49306\tvalidation_1-rmse:1.18516\n",
      "[25]\tvalidation_0-rmse:2.47767\tvalidation_1-rmse:1.17546\n",
      "[26]\tvalidation_0-rmse:2.46237\tvalidation_1-rmse:1.17433\n",
      "[27]\tvalidation_0-rmse:2.44729\tvalidation_1-rmse:1.17359\n",
      "[28]\tvalidation_0-rmse:2.43290\tvalidation_1-rmse:1.16613\n",
      "[29]\tvalidation_0-rmse:2.41856\tvalidation_1-rmse:1.16718\n",
      "[30]\tvalidation_0-rmse:2.40486\tvalidation_1-rmse:1.16733\n",
      "[31]\tvalidation_0-rmse:2.39139\tvalidation_1-rmse:1.16907\n",
      "[32]\tvalidation_0-rmse:2.37830\tvalidation_1-rmse:1.16291\n",
      "[33]\tvalidation_0-rmse:2.36584\tvalidation_1-rmse:1.15687\n",
      "[34]\tvalidation_0-rmse:2.35306\tvalidation_1-rmse:1.15775\n",
      "[35]\tvalidation_0-rmse:2.34090\tvalidation_1-rmse:1.16060\n",
      "[36]\tvalidation_0-rmse:2.32905\tvalidation_1-rmse:1.16580\n",
      "[37]\tvalidation_0-rmse:2.31779\tvalidation_1-rmse:1.16901\n",
      "[38]\tvalidation_0-rmse:2.30589\tvalidation_1-rmse:1.16358\n",
      "[39]\tvalidation_0-rmse:2.29460\tvalidation_1-rmse:1.15807\n",
      "[40]\tvalidation_0-rmse:2.28395\tvalidation_1-rmse:1.15331\n",
      "[41]\tvalidation_0-rmse:2.27326\tvalidation_1-rmse:1.15913\n",
      "[42]\tvalidation_0-rmse:2.26286\tvalidation_1-rmse:1.16364\n",
      "[43]\tvalidation_0-rmse:2.25225\tvalidation_1-rmse:1.16674\n",
      "[44]\tvalidation_0-rmse:2.24209\tvalidation_1-rmse:1.16254\n",
      "[45]\tvalidation_0-rmse:2.23196\tvalidation_1-rmse:1.16797\n",
      "[46]\tvalidation_0-rmse:2.22202\tvalidation_1-rmse:1.17238\n",
      "[47]\tvalidation_0-rmse:2.21256\tvalidation_1-rmse:1.16802\n",
      "[48]\tvalidation_0-rmse:2.20305\tvalidation_1-rmse:1.17431\n",
      "[49]\tvalidation_0-rmse:2.19347\tvalidation_1-rmse:1.17975\n",
      "[50]\tvalidation_0-rmse:2.18441\tvalidation_1-rmse:1.18705\n",
      "[51]\tvalidation_0-rmse:2.17529\tvalidation_1-rmse:1.18333\n",
      "[52]\tvalidation_0-rmse:2.16653\tvalidation_1-rmse:1.18847\n",
      "[53]\tvalidation_0-rmse:2.15805\tvalidation_1-rmse:1.18606\n",
      "[54]\tvalidation_0-rmse:2.14931\tvalidation_1-rmse:1.19311\n",
      "[55]\tvalidation_0-rmse:2.14046\tvalidation_1-rmse:1.19855\n",
      "[56]\tvalidation_0-rmse:2.13240\tvalidation_1-rmse:1.19690\n",
      "[57]\tvalidation_0-rmse:2.12459\tvalidation_1-rmse:1.20263\n",
      "[58]\tvalidation_0-rmse:2.11633\tvalidation_1-rmse:1.20791\n",
      "[59]\tvalidation_0-rmse:2.10856\tvalidation_1-rmse:1.20612\n",
      "[60]\tvalidation_0-rmse:2.10108\tvalidation_1-rmse:1.21375\n",
      "[61]\tvalidation_0-rmse:2.09351\tvalidation_1-rmse:1.21161\n",
      "[62]\tvalidation_0-rmse:2.08583\tvalidation_1-rmse:1.21930\n",
      "[63]\tvalidation_0-rmse:2.07830\tvalidation_1-rmse:1.22588\n",
      "[64]\tvalidation_0-rmse:2.07090\tvalidation_1-rmse:1.22314\n",
      "[65]\tvalidation_0-rmse:2.06353\tvalidation_1-rmse:1.22967\n",
      "[66]\tvalidation_0-rmse:2.05665\tvalidation_1-rmse:1.23718\n",
      "[67]\tvalidation_0-rmse:2.04939\tvalidation_1-rmse:1.23350\n",
      "[68]\tvalidation_0-rmse:2.04204\tvalidation_1-rmse:1.24117\n",
      "[69]\tvalidation_0-rmse:2.03540\tvalidation_1-rmse:1.24868\n",
      "[70]\tvalidation_0-rmse:2.02849\tvalidation_1-rmse:1.24638\n",
      "[71]\tvalidation_0-rmse:2.02130\tvalidation_1-rmse:1.25226\n",
      "[72]\tvalidation_0-rmse:2.01481\tvalidation_1-rmse:1.25873\n",
      "[73]\tvalidation_0-rmse:2.00806\tvalidation_1-rmse:1.25625\n",
      "[74]\tvalidation_0-rmse:2.00114\tvalidation_1-rmse:1.26363\n",
      "[75]\tvalidation_0-rmse:1.99458\tvalidation_1-rmse:1.27123\n",
      "[76]\tvalidation_0-rmse:1.98844\tvalidation_1-rmse:1.27775\n",
      "[77]\tvalidation_0-rmse:1.98178\tvalidation_1-rmse:1.28530\n",
      "[78]\tvalidation_0-rmse:1.97532\tvalidation_1-rmse:1.28141\n",
      "[79]\tvalidation_0-rmse:1.96981\tvalidation_1-rmse:1.28733\n",
      "[80]\tvalidation_0-rmse:1.96376\tvalidation_1-rmse:1.28420\n",
      "[81]\tvalidation_0-rmse:1.95786\tvalidation_1-rmse:1.29011\n",
      "[82]\tvalidation_0-rmse:1.95158\tvalidation_1-rmse:1.28689\n",
      "[83]\tvalidation_0-rmse:1.94582\tvalidation_1-rmse:1.29301\n",
      "[84]\tvalidation_0-rmse:1.94006\tvalidation_1-rmse:1.30085\n",
      "[85]\tvalidation_0-rmse:1.93377\tvalidation_1-rmse:1.29755\n",
      "[86]\tvalidation_0-rmse:1.92822\tvalidation_1-rmse:1.30327\n",
      "[87]\tvalidation_0-rmse:1.92161\tvalidation_1-rmse:1.31079\n",
      "[88]\tvalidation_0-rmse:1.91520\tvalidation_1-rmse:1.31859\n",
      "[89]\tvalidation_0-rmse:1.90934\tvalidation_1-rmse:1.31456\n",
      "[90]\tvalidation_0-rmse:1.90418\tvalidation_1-rmse:1.32063\n",
      "[91]\tvalidation_0-rmse:1.89823\tvalidation_1-rmse:1.32851\n",
      "[92]\tvalidation_0-rmse:1.89270\tvalidation_1-rmse:1.32482\n",
      "[93]\tvalidation_0-rmse:1.88704\tvalidation_1-rmse:1.32439\n",
      "[94]\tvalidation_0-rmse:1.88165\tvalidation_1-rmse:1.33115\n",
      "[95]\tvalidation_0-rmse:1.87658\tvalidation_1-rmse:1.33700\n",
      "[96]\tvalidation_0-rmse:1.87139\tvalidation_1-rmse:1.34277\n",
      "[97]\tvalidation_0-rmse:1.86543\tvalidation_1-rmse:1.35122\n",
      "[98]\tvalidation_0-rmse:1.85997\tvalidation_1-rmse:1.34842\n",
      "[99]\tvalidation_0-rmse:1.85497\tvalidation_1-rmse:1.35408\n",
      "[100]\tvalidation_0-rmse:1.85026\tvalidation_1-rmse:1.36082\n",
      "[101]\tvalidation_0-rmse:1.84455\tvalidation_1-rmse:1.36849\n",
      "[102]\tvalidation_0-rmse:1.83974\tvalidation_1-rmse:1.37528\n",
      "[103]\tvalidation_0-rmse:1.83414\tvalidation_1-rmse:1.38286\n",
      "[104]\tvalidation_0-rmse:1.82828\tvalidation_1-rmse:1.38070\n",
      "[105]\tvalidation_0-rmse:1.82387\tvalidation_1-rmse:1.37876\n",
      "[106]\tvalidation_0-rmse:1.81912\tvalidation_1-rmse:1.38467\n",
      "[107]\tvalidation_0-rmse:1.81431\tvalidation_1-rmse:1.39043\n",
      "[108]\tvalidation_0-rmse:1.80925\tvalidation_1-rmse:1.38631\n",
      "[109]\tvalidation_0-rmse:1.80370\tvalidation_1-rmse:1.39481\n",
      "[110]\tvalidation_0-rmse:1.79899\tvalidation_1-rmse:1.40023\n",
      "[111]\tvalidation_0-rmse:1.79457\tvalidation_1-rmse:1.40697\n",
      "[112]\tvalidation_0-rmse:1.78958\tvalidation_1-rmse:1.40268\n",
      "[113]\tvalidation_0-rmse:1.78419\tvalidation_1-rmse:1.40972\n",
      "[114]\tvalidation_0-rmse:1.77961\tvalidation_1-rmse:1.41509\n",
      "[115]\tvalidation_0-rmse:1.77459\tvalidation_1-rmse:1.41198\n",
      "[116]\tvalidation_0-rmse:1.77017\tvalidation_1-rmse:1.41724\n",
      "[117]\tvalidation_0-rmse:1.76500\tvalidation_1-rmse:1.42468\n",
      "[118]\tvalidation_0-rmse:1.76033\tvalidation_1-rmse:1.43123\n",
      "[119]\tvalidation_0-rmse:1.75559\tvalidation_1-rmse:1.42818\n",
      "[120]\tvalidation_0-rmse:1.75151\tvalidation_1-rmse:1.43478\n",
      "[121]\tvalidation_0-rmse:1.74694\tvalidation_1-rmse:1.43157\n",
      "[122]\tvalidation_0-rmse:1.74193\tvalidation_1-rmse:1.43979\n",
      "[123]\tvalidation_0-rmse:1.73763\tvalidation_1-rmse:1.44510\n",
      "[124]\tvalidation_0-rmse:1.73288\tvalidation_1-rmse:1.45096\n",
      "[125]\tvalidation_0-rmse:1.72792\tvalidation_1-rmse:1.44768\n",
      "[126]\tvalidation_0-rmse:1.72364\tvalidation_1-rmse:1.44460\n",
      "[127]\tvalidation_0-rmse:1.71929\tvalidation_1-rmse:1.45097\n",
      "[128]\tvalidation_0-rmse:1.71430\tvalidation_1-rmse:1.45902\n",
      "[129]\tvalidation_0-rmse:1.71045\tvalidation_1-rmse:1.46470\n",
      "[130]\tvalidation_0-rmse:1.70606\tvalidation_1-rmse:1.46149\n",
      "[131]\tvalidation_0-rmse:1.70109\tvalidation_1-rmse:1.46897\n",
      "[132]\tvalidation_0-rmse:1.69697\tvalidation_1-rmse:1.47411\n",
      "[133]\tvalidation_0-rmse:1.69278\tvalidation_1-rmse:1.48033\n",
      "[134]\tvalidation_0-rmse:1.68805\tvalidation_1-rmse:1.48768\n",
      "[135]\tvalidation_0-rmse:1.68360\tvalidation_1-rmse:1.49140\n",
      "[136]\tvalidation_0-rmse:1.67904\tvalidation_1-rmse:1.49699\n",
      "[137]\tvalidation_0-rmse:1.67511\tvalidation_1-rmse:1.50271\n",
      "[138]\tvalidation_0-rmse:1.67081\tvalidation_1-rmse:1.49945\n",
      "[139]\tvalidation_0-rmse:1.66713\tvalidation_1-rmse:1.50484\n",
      "[140]\tvalidation_0-rmse:1.66290\tvalidation_1-rmse:1.50842\n",
      "Stopping. Best iteration:\n",
      "[40]\tvalidation_0-rmse:2.28395\tvalidation_1-rmse:1.15331\n",
      "\n",
      "[17:23:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, gamma=None,\n",
       "                                    gpu_id=None, importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=100, n_jobs=...\n",
       "                                    reg_alpha=None, reg_lambda=None,\n",
       "                                    scale_pos_weight=None, subsample=None,\n",
       "                                    tree_method=None, validate_parameters=None,\n",
       "                                    verbosity=None),\n",
       "             n_jobs=4,\n",
       "             param_grid={'colsample_bytree': [0.7, 0.8],\n",
       "                         'learning_rate': [0.01, 0.03, 0.05],\n",
       "                         'max_depth': [3, 4, 5, 6, 7, 7],\n",
       "                         'min_child_weight': [4], 'n_estimators': [500],\n",
       "                         'nthread': [4], 'objective': ['reg:linear'],\n",
       "                         'silent': [1], 'subsample': [1]},\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.7, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.03, max_delta_step=0, max_depth=5,\n",
       "             min_child_weight=4, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=500, n_jobs=4, nthread=4, num_parallel_tree=1,\n",
       "             objective='reg:linear', random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "             scale_pos_weight=1, silent=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CatFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите модель классификации катбуста на предложенных данных и верните обученную модель. \n",
    "\n",
    "Воспользуйтесь встроенной обработкой категориальных признаков. Не забудьте обработать Nan значения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "def catfeatures(df: pd.DataFrame):\n",
    "    x_train = df.drop('dep_delayed_15min',axis=1)\n",
    "    y_train = df['dep_delayed_15min'].replace({'N' : 0, 'Y' : 1})\n",
    "    clf = CatBoostClassifier(iterations=100,\n",
    "    custom_loss=['Accuracy'],\n",
    "    random_seed=42,\n",
    "    logging_level='Silent'\n",
    ")\n",
    "    clf.fit(x_train,y_train, cat_features=['Month', 'DayofMonth', 'DayOfWeek', 'UniqueCarrier', 'Origin', 'Dest'])\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>dep_delayed_15min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c-8</td>\n",
       "      <td>c-21</td>\n",
       "      <td>c-7</td>\n",
       "      <td>1934</td>\n",
       "      <td>AA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DFW</td>\n",
       "      <td>732</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c-4</td>\n",
       "      <td>c-20</td>\n",
       "      <td>c-3</td>\n",
       "      <td>1548</td>\n",
       "      <td>US</td>\n",
       "      <td>PIT</td>\n",
       "      <td>MCO</td>\n",
       "      <td>834</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c-9</td>\n",
       "      <td>c-2</td>\n",
       "      <td>c-5</td>\n",
       "      <td>1422</td>\n",
       "      <td>XE</td>\n",
       "      <td>RDU</td>\n",
       "      <td>CLE</td>\n",
       "      <td>416</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c-11</td>\n",
       "      <td>c-25</td>\n",
       "      <td>c-6</td>\n",
       "      <td>1015</td>\n",
       "      <td>OO</td>\n",
       "      <td>DEN</td>\n",
       "      <td>MEM</td>\n",
       "      <td>872</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c-10</td>\n",
       "      <td>c-7</td>\n",
       "      <td>c-6</td>\n",
       "      <td>1828</td>\n",
       "      <td>WN</td>\n",
       "      <td>MDW</td>\n",
       "      <td>OMA</td>\n",
       "      <td>423</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Month DayofMonth DayOfWeek  DepTime UniqueCarrier Origin Dest  Distance  \\\n",
       "0   c-8       c-21       c-7     1934            AA    ATL  DFW       732   \n",
       "1   c-4       c-20       c-3     1548            US    PIT  MCO       834   \n",
       "2   c-9        c-2       c-5     1422            XE    RDU  CLE       416   \n",
       "3  c-11       c-25       c-6     1015            OO    DEN  MEM       872   \n",
       "4  c-10        c-7       c-6     1828            WN    MDW  OMA       423   \n",
       "\n",
       "  dep_delayed_15min  \n",
       "0                 N  \n",
       "1                 N  \n",
       "2                 N  \n",
       "3                 N  \n",
       "4                 Y  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well Done\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/flight_delays_train.csv')\n",
    "df_train = df[:7000]\n",
    "\n",
    "t1 = time.time()\n",
    "model = catfeatures(df_train)\n",
    "t2 = time.time()\n",
    "\n",
    "assert t2 - t1 < 10\n",
    "assert type(model) == catboost.CatBoostClassifier\n",
    "\n",
    "df_test = pd.read_csv('data/flight_catfeature_test.csv')\n",
    "df_test = df_test.drop('Unnamed: 0', axis=1)\n",
    "X_test = df_test.drop('dep_delayed_15min',axis=1)\n",
    "y_test = df_test['dep_delayed_15min']\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "assert accuracy_score(y_test, y_pred) > 0.80 \n",
    "print('Well Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8124"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Производные для регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть мы хотим бустить регрессию со стандартной функцией потерь $MSE$:\n",
    "\n",
    "$$\\mathcal{L}(a, x,y) = (a(x_i) - y_i)^2$$\n",
    "\n",
    "Необходимо найти через взятие производных:\n",
    "\n",
    "1. Константный вектор $[f_0]_{i=1}^{N}$\n",
    "$$f_0(x) = \\arg\\min_{ c\\in \\mathbb{R}} \\sum_{i=1}^n \\mathcal{L}(c, y_i)$$ \n",
    "\n",
    "2. Градиенты функции потерь\n",
    "$$g_{i}^{t} = -\\Big[\\frac{\\partial \\mathcal{L}(f_t, x_i, y_i)}{\\partial f_t(x_i)}\\Big]_{i=1}^N$$\n",
    "\n",
    "3. Коэффициенты при композиции \n",
    "$$\\alpha_{t + 1} = \\arg\\min_\\alpha \\sum_{i=1}^N \\mathcal{L}(f_{t}(x_i) + \\alpha b_{t+1}(x_i), y_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(y_i: np.array) -> float:\n",
    "    f_0 = y_i.mean()\n",
    "    return f_0\n",
    "\n",
    "def grad(a: np.array, y: np.array) -> np.array:\n",
    "    g = -2*(a-y)\n",
    "    return g\n",
    "\n",
    "def alpha(f :np.array, b: np.array, y: np.array) -> float:\n",
    "    alpha = np.dot(f-y,b)/(np.dot(b,b))\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well Done!\n"
     ]
    }
   ],
   "source": [
    "y = np.array([1, 2, 3])\n",
    "f = np.array([2, 2, 2])\n",
    "b = np.array([0, 2, 4])\n",
    "\n",
    "f_0 = init(y)\n",
    "g = grad(f,y)\n",
    "al = alpha(f,b,y)\n",
    "\n",
    "\n",
    "assert np.abs(f_0 - 2.0)   < 1e-9\n",
    "assert_array_almost_equal(g, np.array([-2, 0, 2]))\n",
    "assert np.abs(al - (-0.2)) < 1e-9\n",
    "######################################################\n",
    "y = np.arange(20)\n",
    "f = np.ones(20) * 10\n",
    "b = np.arange(20) - 1\n",
    "\n",
    "f_0 = init(y)\n",
    "g = grad(f,y)\n",
    "al = alpha(f,b,y)\n",
    "\n",
    "\n",
    "assert np.abs(f_0 - 9.5)   < 1e-2\n",
    "assert_array_almost_equal(g, np.arange(-20,20, 2))\n",
    "assert np.abs(al - (-0.2748)) < 1e-2\n",
    "print('Well Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. GradientBoosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте градиентный бустинг на решающих деревьях для регрессии с логгированием.Верните модель, которая будет хранить в себе `n_estimatos` обученных деревьев и коэффициенты, чтобы с их помощью потом найти результат предсказания.\n",
    "\n",
    "Также необходимо реализовать логгирование в течение обучения.\n",
    "* `self.estimators` - лист c деревьями\n",
    "* `self.alpha` - лист с коэффициентами альфа\n",
    "* `self.f_list` - лист со значениями комбинаций алгоритма $f_T(x_i) = f_0(x_i) + \\sum_{t=1}^{T}\\alpha_tb_t(x_i)$\n",
    "* `self.g_list` - лист с векторами градиентов на каждой итерации $g_{i}^{t} = -\\Big[\\frac{\\partial \\mathcal{L}(f_t, x_i, y_i)}{\\partial f_t(x_i)}\\Big]_{i=1}^N$\n",
    "* `self.b_list` - лист со значениями базового обучаемого дерева на тренировачной выборке на каждой итерации \n",
    "\n",
    "Примечания:\n",
    "* Обрывать алгоритм не нужно, необходимо обучить все деревья.\n",
    "* Начальный константный вектор из $f_0$ логгировать не нужно, однако не забудьте его добавить в `predict` c нужным количеством объектов!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor as DTR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "class MyGradBoost():\n",
    "    def __init__(self, n_estimators=10, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.estimators_ = np.array([DTR(max_depth=self.max_depth) for _ in range(n_estimators)])\n",
    "        self.alpha = []\n",
    "        self.f_list = []\n",
    "        self.b_list = []\n",
    "        self.g_list = []\n",
    "        \n",
    "    def fit(self, X_train: np.array, y_train: np.array): \n",
    "        f_0 = np.array([init(y_train) for i in range(len(y_train))])\n",
    "        f_current = f_0\n",
    "        for t in range(self.n_estimators):\n",
    "            g_t = grad(f_current, y_train)\n",
    "            self.estimators_[t].fit(X_train, g_t)\n",
    "            b_t = self.estimators_[t].predict(X_train)\n",
    "            a_t = alpha(f_current, b_t, y_train)\n",
    "            f_current = f_current + a_t*b_t\n",
    "            self.f_list.append(f_current)\n",
    "            self.alpha.append(a_t)\n",
    "            self.b_list.append(b_t)\n",
    "            self.g_list.append(g_t)\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X_test) -> np.array:\n",
    "        y_pred = np.array([init(y_train) for i in range(len(X_test))])\n",
    "        for t in range(self.n_estimators):\n",
    "            y_pred = y_pred + (self.alpha[t] * self.estimators_[t].predict(X_test))\n",
    "        return y_pred\n",
    "    \n",
    "    def score(self, X_test, y_test)-> np.array:\n",
    "        return mean_squared_error(self.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-c3d2f779e71e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m                     max_depth=1).fit(X_train, y_train)\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.017\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Well Done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_estimators = 2\n",
    "max_depth=3\n",
    "X_train = np.array([[0], [1], [2], [3], [4]])\n",
    "y_train = np.array([0, 2, 4, 2, 0])\n",
    "X_test  = np.array([[1.2], [2.3]])\n",
    "y_test  = np.array([2.2, 3.7])\n",
    "\n",
    "model = MyGradBoost(n_estimators=n_estimators, max_depth=max_depth).fit(X_train, y_train)\n",
    "#assert model.score(X_test, y_test) < 0.2\n",
    "######################################################\n",
    "n_train, n_test, noise = 150, 1000, 0.1\n",
    "# Generate data\n",
    "def f(x):\n",
    "    x = x.ravel()\n",
    "    return np.exp(-x ** 2) + 1.5 * np.exp(-(x - 2) ** 2)\n",
    "\n",
    "def generate(n_samples, noise):\n",
    "    X = np.random.rand(n_samples) * 10 - 5\n",
    "    X = np.sort(X).ravel()\n",
    "    y = np.exp(-X ** 2) + 1.5 * np.exp(-(X - 2) ** 2)\\\n",
    "        + np.random.normal(0.0, noise, n_samples)\n",
    "    X = X.reshape((n_samples, 1))\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = generate(n_samples=n_train, noise=noise)\n",
    "X_test, y_test = generate(n_samples=n_test, noise=noise)\n",
    "\n",
    "\n",
    "model = MyGradBoost().fit(X_train, y_train)\n",
    "\n",
    "#assert model.score(X_test, y_test) < 0.025\n",
    "\n",
    "\n",
    "model = MyGradBoost(n_estimators=100, \n",
    "                    max_depth=1).fit(X_train, y_train)\n",
    "\n",
    "assert model.score(X_test, y_test) < 0.017\n",
    "print('Well Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Самопроверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def predict_and_plot(model, X_test, y_test, title):\n",
    "    y_predict = model.predict(X_test)\n",
    "\n",
    "    plt.plot(X_test, f(X_test), \"b\")\n",
    "    plt.scatter(X_train, y_train, c=\"b\", s=20)\n",
    "    plt.plot(X_test, y_predict, \"g\", lw=2)\n",
    "    plt.xlim([-5, 5])\n",
    "    plt.title(\"{} Loss: {:2f}\".format(title, model.score(X_test, y_test)))\n",
    "    plt.grid()\n",
    "\n",
    "\n",
    "\n",
    "model = MyGradBoost(n_estimators=30, \n",
    "                    max_depth=1).fit(X_train, y_train)\n",
    "\n",
    "ind =  [1,3,5,10,15,30]\n",
    "\n",
    "# GradientBoostingRegressor\n",
    "plt.plot(X_test, f(X_test), \"b\")\n",
    "plt.scatter(X_train, y_train, c=\"b\", s=20)\n",
    "n_est = [1,3,5,10,15,30]\n",
    "f = np.array(model.f_list)\n",
    "for i, n in enumerate(n_est):\n",
    "    colors = ['g', 'r', 'c', 'm', 'y', 'k']\n",
    "    plt.plot(X_train, f[n-1], color=colors[i], label=\"tree count={}\".format(n))\n",
    "\n",
    "plt.xlim([-5, 5])   \n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
